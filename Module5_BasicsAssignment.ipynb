{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0a856f0-7893-46e7-861f-ce10ecd9ac59",
   "metadata": {},
   "source": [
    "Michael O'Donnell - 02/07/2024\n",
    "\n",
    "STC 510 - Module Basics Assignment \n",
    "\n",
    "The purpose of this program is to find if the Naive Bayes algorithm can somewhat accurately sort whether a question from Jeopardy is easy or hard to answer. To do so the program imports a JSON file that contains data from the television show Jeopardy. Once that data set is imported, the program then must put that JSON data into a dataframe for manipulation. After that the program then cleans the the value column to turn the values into an integer becuase the program needs to be able to compare the integers and not strings. \n",
    "\n",
    "Since determining whether a question from a game show is quite biased I Googled \"what makes a question in Jeopardy hard.\" Doing so yielded this Medium Article:\n",
    "\n",
    "https://medium.com/@pollockcolin/jeopardy-question-difficulty-1bba47770bc6\n",
    "\n",
    "Where the author discusses Jeopardy and machine learning. In the article I was able to take some insight from where people on a Jeopardy site started getting more questions wrong then right. The author notes this by visualizing it in a graph by Jeopardy round and dollar amount. This is where my own bias came in and I made the cutoff at 50% correct to consider a question hard after that. Although this includes my own bias, I believe this cuts off the monumental amount of bias I could have included by trying to code the questions based on themes or something of that nature. \n",
    "\n",
    "So my logic for the cutoff was this: A question will be considered easy IF the ROUND is 'Jeopardy!' AND the 'value' is 800 or less OR if the ROUND is 'Double Jeopardy!' and the 'value' is 1200 or less. This way if the round is in Final Jeopardy or a Tiebreaker they will be considered hard since the show aims to make those harder. Following this line of reasoning a long with the graphs the author provided, I was able to get the Naive Bayes to classify an easy question that I assumed is easy from the data of the author 79% right. That is quite more accurate than the 50/50 chance of guessing whether a question will be easy or hard so I am content with this. \n",
    "\n",
    "I also used this source for importing the JSON file:\n",
    "\n",
    "https://www.freecodecamp.org/news/loading-a-json-file-in-python-how-to-read-and-parse-json/\n",
    "\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe14f6b0-69df-4e08-8542-dfbb4e32fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statements\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d34c992-6e0f-4cd3-9691-cc654ae5400a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting the stop words\n",
    "english_stopwords = set(stopwords.words('english') + list(punctuation) + ['..','...','nbsp','n\\'t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d7ad1df-72a7-461d-ba0f-5ae6a4c8529b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iniatalizing the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b026e9d-2055-49ee-ac14-d19a64475a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bringing in the jeopardy JSON file\n",
    "with open('jeopardy.json') as jeopardy_file:\n",
    "    jeopardy_contents = jeopardy_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "592dfa04-7375-413a-b6ef-5d80b4a2e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing the jeopardy JSON file so it can read by python and put into a dataframe\n",
    "parsed_jeopardy = json.loads(jeopardy_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8743caed-10b3-475d-8b3b-93576c216d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#puts the JSON questions into a dataframe\n",
    "df = pd.DataFrame(parsed_jeopardy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05ed236f-41f0-488e-b4af-a5cb7391a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleans the value column and sets the values to integers\n",
    "df['value'] = df['value'].str.replace('$','')\n",
    "df['value'] = df['value'].str.replace(',','')\n",
    "df['value'] = df['value'].str.strip()\n",
    "df['value'] = pd.to_numeric(df['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cff51058-46a0-4949-a0a2-68e8e57fd41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adds a new column that uses the explained above logic that gives easy questions a 1 and hard questions a 0\n",
    "df['difficulty'] = np.where(((df['round']=='Jeopardy!') & (df['value'] <= 800)) | ((df['round']=='Double Jeopardy!') & (df['value'] <= 1200)),1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d14d26a6-9a49-4e35-b7f2-ac7fcfef72f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a function that takes each cell given to it from a dataframe that then goes and makes it lowercase,\n",
    "# tokenizes it, lemmantizes it and puts it back into the original string of the cell \n",
    "def manipulate_text(text):\n",
    "    text = text.lower()\n",
    "    toke_text = word_tokenize(text)\n",
    "    wordlist = []\n",
    "    for word in toke_text:\n",
    "        if word not in english_stopwords:\n",
    "            wordlist.append(word)\n",
    "    wordlist2 = []\n",
    "    for eachword in wordlist:\n",
    "        wordlist2.append(lemmatizer.lemmatize(eachword))\n",
    "    text = [' '.join(wordlist2)]\n",
    "    text = str(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4355283-5419-4cea-9d0b-67f0e5f67322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This puts the column of question that I want to manipulate for training in the above function\n",
    "df['question'] = df['question'].apply(manipulate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e357abf-401f-413a-a47a-b94f2093b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is taken from the lecture, but it splits up the question and difficulty into training and testing sets\n",
    "#so the program can see how accurate the algorithm is at classifying the text\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.question, df.difficulty, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "103bd537-22bc-446f-b72e-176ce9f48725",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This vectorizes and trains/tests the algorithm on the question cells\n",
    "tfidf_vectorizer = TfidfVectorizer(use_idf=True)\n",
    "X_train_tf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "26d7293a-64e7-452b-acbd-b7b36033d267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This sees how well the test holds up against the training data\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_tf, Y_train)\n",
    "predictions = naive_bayes.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7414531f-fecb-49c0-8048-360071968905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7932992827245404\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ', accuracy_score(Y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
